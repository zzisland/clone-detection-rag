import streamlit as st
import sys
import os
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent / "src"))

from rag import CloneDetectionRAG
from ingest import DataIngestor
from config import Config

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä»£ç å…‹éš†æ£€æµ‹RAGåŠ©æ‰‹",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSS - ä¼˜åŒ–åŠ è½½é€Ÿåº¦
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #ff7f0e;
        margin-bottom: 1rem;
        text-align: center;
    }
    .source-badge {
        background-color: #e3f2fd;
        padding: 0.25rem 0.5rem;
        border-radius: 0.25rem;
        font-size: 0.875rem;
        margin: 0.125rem;
        display: inline-block;
    }
    .confidence-high { color: #4caf50; font-weight: bold; }
    .confidence-medium { color: #ff9800; font-weight: bold; }
    .confidence-low { color: #f44336; font-weight: bold; }
    
    /* åŠ é€Ÿæ¸²æŸ“ */
    .stApp { animation: none !important; }
    .element-container { animation: none !important; }
</style>
""", unsafe_allow_html=True)

def initialize_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'rag_system' not in st.session_state:
        st.session_state.rag_system = None
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'data_ingested' not in st.session_state:
        st.session_state.data_ingested = False
    if 'system_loading' not in st.session_state:
        st.session_state.system_loading = False
    if 'processing' not in st.session_state:
        st.session_state.processing = False
    if 'current_input' not in st.session_state:
        st.session_state.current_input = ""
    if 'selected_model' not in st.session_state:
        st.session_state.selected_model = "1.5B"
    if 'trigger_send' not in st.session_state:
        st.session_state.trigger_send = False

def load_rag_system(model_size="1.5B"):
    """åŠ è½½RAGç³»ç»Ÿï¼ˆå»¶è¿ŸåŠ è½½ï¼‰"""
    if st.session_state.rag_system is None:
        # åˆ›å»ºåŠ è½½ç•Œé¢
        loading_placeholder = st.empty()
        
        with loading_placeholder.container():
            st.info(f"ğŸš€ æ­£åœ¨åŠ è½½ {model_size} æ¨¡å‹ï¼Œè¯·ç¨å€™...")
            
            # åˆ›å»ºè¿›åº¦æ¡
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                # æ­¥éª¤ 1: åˆå§‹åŒ–
                status_text.text("â³ [1/4] åˆå§‹åŒ–ç³»ç»Ÿ...")
                progress_bar.progress(10)
                
                # æ­¥éª¤ 2: åŠ è½½ Tokenizer
                model_info = {
                    "1.5B": "çº¦10MB",
                    "7B": "çº¦10MB"
                }
                status_text.text(f"â³ [2/4] åŠ è½½ Tokenizerï¼ˆé¦–æ¬¡éœ€ä¸‹è½½ï¼Œ{model_info.get(model_size, 'çº¦10MB')}ï¼‰...")
                progress_bar.progress(25)
                
                # æ­¥éª¤ 3: åŠ è½½æ¨¡å‹
                model_size_info = {
                    "1.5B": "çº¦3GB",
                    "7B": "çº¦14GB"
                }
                status_text.text(f"â³ [3/4] åŠ è½½ LLM æ¨¡å‹ï¼ˆé¦–æ¬¡éœ€ä¸‹è½½ï¼Œ{model_size_info.get(model_size, 'çº¦3GB')}ï¼Œä½¿ç”¨é•œåƒåŠ é€Ÿï¼‰...")
                progress_bar.progress(40)
                
                # å®é™…åŠ è½½ï¼ˆä¼ å…¥æ¨¡å‹å¤§å°å‚æ•°ï¼‰
                st.session_state.rag_system = CloneDetectionRAG(model_size=model_size)
                st.session_state.selected_model = model_size
                
                # æ­¥éª¤ 4: å®Œæˆ
                progress_bar.progress(100)
                status_text.text("âœ… [4/4] ç³»ç»ŸåŠ è½½å®Œæˆï¼")
                
                # æ¸…é™¤åŠ è½½ç•Œé¢
                import time
                time.sleep(1)
                loading_placeholder.empty()
                
                st.success(f"âœ… RAG ç³»ç»Ÿå·²å°±ç»ªï¼å½“å‰æ¨¡å‹: {model_size}")
                return True
                
            except Exception as e:
                loading_placeholder.empty()
                st.error(f"âŒ åŠ è½½å¤±è´¥: {e}")
                st.info("ğŸ’¡ æç¤ºï¼šé¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹ï¼Œè¯·ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸ã€‚")
                return False
    return True

def sidebar():
    """ä¾§è¾¹æ  - ä¼˜åŒ–ç‰ˆ"""
    st.sidebar.title("ğŸ”§ æ§åˆ¶é¢æ¿")
    
    # ç³»ç»ŸçŠ¶æ€ - ç®€åŒ–æ˜¾ç¤º
    with st.sidebar.expander("ğŸ“Š ç³»ç»ŸçŠ¶æ€", expanded=True):
        if st.session_state.rag_system:
            st.success(f"âœ… æ¨¡å‹: {st.session_state.selected_model}")
        else:
            st.warning("âš ï¸ æœªåŠ è½½")
        
        if st.session_state.data_ingested:
            st.success("âœ… æ•°æ®å·²å°±ç»ª")
        else:
            st.info("ğŸ’¡ éœ€è¦æ‘„å–æ•°æ®")
    
    # æ•°æ®ç®¡ç†
    with st.sidebar.expander("ğŸ“š æ•°æ®ç®¡ç†"):
        if st.button("é‡æ–°æ‘„å–æ•°æ®", type="primary", use_container_width=True):
            with st.spinner("å¤„ç†ä¸­..."):
                try:
                    ingestor = DataIngestor()
                    vector_store = ingestor.ingest_all_data()
                    if vector_store:
                        st.session_state.data_ingested = True
                        st.success("å®Œæˆï¼")
                    else:
                        st.error("å¤±è´¥ï¼")
                except Exception as e:
                    st.error(f"é”™è¯¯: {str(e)[:50]}...")
    
    # å¿«é€Ÿæ“ä½œ - ç®€åŒ–
    with st.sidebar.expander("ğŸš€ ç¤ºä¾‹é—®é¢˜"):
        questions = [
            "ä»€ä¹ˆæ˜¯ä»£ç å…‹éš†æ£€æµ‹ï¼Ÿ",
            "Type-1/2/3å…‹éš†çš„åŒºåˆ«",
            "ASTå’ŒTokenæ–¹æ³•æ¯”è¾ƒ",
            "å¦‚ä½•è¯„ä¼°æ£€æµ‹å·¥å…·ï¼Ÿ"
        ]
        
        selected = st.selectbox("é€‰æ‹©ï¼š", questions, label_visibility="collapsed")
        
        if st.button("ä½¿ç”¨æ­¤é—®é¢˜", use_container_width=True):
            st.session_state.current_input = selected
            st.session_state.trigger_send = True
            st.rerun()

def chat_interface():
    """èŠå¤©ç•Œé¢ - ä¼˜åŒ–ç‰ˆ"""
    st.markdown('<h1 class="main-header">ğŸ” ä»£ç å…‹éš†æ£€æµ‹RAGåŠ©æ‰‹</h1>', unsafe_allow_html=True)
    
    # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
    if st.session_state.rag_system is None:
        st.markdown('<p class="sub-header">ğŸ‘‹ æ¬¢è¿ï¼è¯·é€‰æ‹©æ¨¡å‹å¼€å§‹ä½¿ç”¨</p>', unsafe_allow_html=True)
        
        # æ¨¡å‹é€‰æ‹© - ç®€åŒ–ç‰ˆ
        col1, col2 = st.columns(2)
        
        with col1:
            with st.container():
                st.markdown("### ğŸš€ è½»é‡ç‰ˆ")
                st.markdown("**1.5B æ¨¡å‹**")
                st.caption("âœ… å¿«é€Ÿ | 3GBæ˜¾å­˜ | æ¨è")
                if st.button("é€‰æ‹©", key="1.5b", type="primary", use_container_width=True):
                    load_rag_system("1.5B")
                    st.rerun()
        
        with col2:
            with st.container():
                st.markdown("### ğŸ’ª ä¸“ä¸šç‰ˆ")
                st.markdown("**7B æ¨¡å‹**")
                st.caption("âœ… é«˜æ€§èƒ½ | 14GBæ˜¾å­˜")
                if st.button("é€‰æ‹©", key="7b", use_container_width=True):
                    load_rag_system("7B")
                    st.rerun()
        
        st.info("ğŸ’¡ é¦–æ¬¡ä½¿ç”¨éœ€ä¸‹è½½æ¨¡å‹ï¼Œå·²é…ç½®å›½å†…é•œåƒåŠ é€Ÿ")
        return
    
    # æ˜¾ç¤ºèŠå¤©å†å² - ä¼˜åŒ–æ¸²æŸ“
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            if message["role"] == "assistant":
                # ç®€åŒ–æ¥æºæ˜¾ç¤º
                if message.get("sources"):
                    with st.expander("ğŸ“š æ¥æº", expanded=False):
                        for src in message["sources"][:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                            st.caption(src.split("/")[-1])  # åªæ˜¾ç¤ºæ–‡ä»¶å

def main():
    """ä¸»å‡½æ•°"""
    initialize_session_state()
    
    # ä¾§è¾¹æ 
    sidebar()
    
    # ä¸»ç•Œé¢
    tab1, tab2, tab3 = st.tabs(["ğŸ’¬ å¯¹è¯", "ğŸ“Š ç³»ç»Ÿä¿¡æ¯", "ğŸ”§ é…ç½®"])
    
    with tab1:
        chat_interface()
        
        # èŠå¤©è¾“å…¥åŒºåŸŸ
        st.markdown("---")
        
        # å¤„ç†ç¤ºä¾‹é—®é¢˜è§¦å‘
        trigger_input = None
        if st.session_state.get("trigger_send", False):
            trigger_input = st.session_state.get("current_input", "")
            st.session_state.trigger_send = False
            st.session_state.current_input = ""
        
        # è¾“å…¥åŒºåŸŸ
        with st.form(key="chat_form", clear_on_submit=True):
            col1, col2 = st.columns([4, 1])
            
            with col1:
                # ä¸ä½¿ç”¨ session_state ä½œä¸º valueï¼Œé¿å… setIn é”™è¯¯
                user_input = st.text_input(
                    "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...", 
                    placeholder="ä¾‹å¦‚ï¼šä»€ä¹ˆæ˜¯ä»£ç å…‹éš†æ£€æµ‹ï¼ŸæŒ‰å›è½¦å‘é€",
                    key="user_input_field",
                    label_visibility="collapsed"
                )
            
            with col2:
                send_button = st.form_submit_button(
                    "å‘é€ âœ‰ï¸", 
                    type="primary",
                    use_container_width=True
                )
        
        # å¦‚æœæœ‰è§¦å‘çš„è¾“å…¥ï¼Œä½¿ç”¨å®ƒ
        if trigger_input:
            user_input = trigger_input
            send_button = True
        
        # å¤„ç†ç”¨æˆ·è¾“å…¥
        if send_button and user_input and user_input.strip():
            # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦å·²åŠ è½½
            if st.session_state.rag_system is None:
                st.warning("âš ï¸ è¯·å…ˆé€‰æ‹©å¹¶åˆå§‹åŒ–æ¨¡å‹ï¼ç‚¹å‡»ä¸Šæ–¹çš„æ¨¡å‹é€‰æ‹©æŒ‰é’®å¼€å§‹ã€‚")
            else:
                # è®¾ç½®å¤„ç†çŠ¶æ€
                st.session_state.processing = True
                st.session_state.current_input = ""  # æ¸…ç©ºè¾“å…¥
                
                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
                st.session_state.messages.append({"role": "user", "content": user_input})
                
                # åˆ›å»ºè¿›åº¦æ˜¾ç¤º
                progress_placeholder = st.empty()
                
                try:
                    with progress_placeholder.container():
                        col1, col2, col3 = st.columns([1, 2, 1])
                        with col2:
                            st.info("ğŸ¤” AI æ­£åœ¨æ€è€ƒä¸­...")
                            progress_bar = st.progress(0)
                            status_text = st.empty()
                            
                            # æ­¥éª¤ 1: æ£€ç´¢
                            import time
                            status_text.text("ğŸ“š [1/3] æ£€ç´¢ç›¸å…³æ–‡æ¡£...")
                            progress_bar.progress(20)
                            time.sleep(0.2)
                            
                            progress_bar.progress(40)
                            
                            # æ­¥éª¤ 2: ç”Ÿæˆ
                            status_text.text("ğŸ’­ [2/3] ç”Ÿæˆå›ç­”ä¸­...")
                            progress_bar.progress(50)
                            
                            # å®é™…ç”Ÿæˆå›ç­”
                            result = st.session_state.rag_system.get_chat_response(user_input)
                            
                            progress_bar.progress(90)
                            status_text.text("âœ¨ [3/3] å®Œæˆï¼")
                            progress_bar.progress(100)
                            time.sleep(0.3)
                    
                    # æ¸…é™¤è¿›åº¦æ˜¾ç¤º
                    progress_placeholder.empty()
                    
                    # æ·»åŠ åˆ°æ¶ˆæ¯å†å²
                    assistant_message = {
                        "role": "assistant",
                        "content": result.get("answer", "æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆå›ç­”ã€‚"),
                        "sources": result.get("sources", []),
                        "confidence": result.get("confidence", "medium")
                    }
                    st.session_state.messages.append(assistant_message)
                    
                except Exception as e:
                    progress_placeholder.empty()
                    st.error(f"âŒ ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {str(e)}")
                    st.info("ğŸ’¡ æç¤ºï¼šå¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·å°è¯•é‡æ–°åŠ è½½ç³»ç»Ÿæˆ–é€‰æ‹©å…¶ä»–æ¨¡å‹ã€‚")
                    # ç§»é™¤ç”¨æˆ·æ¶ˆæ¯ï¼ˆå› ä¸ºå¤±è´¥äº†ï¼‰
                    if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
                        st.session_state.messages.pop()
                
                finally:
                    # é‡ç½®å¤„ç†çŠ¶æ€ï¼ˆç¡®ä¿ä¸€å®šä¼šæ‰§è¡Œï¼‰
                    st.session_state.processing = False
                
                # é‡æ–°è¿è¡Œä»¥æ˜¾ç¤ºæ–°æ¶ˆæ¯
                st.rerun()
    
    with tab2:
        st.header("ğŸ“Š ç³»ç»Ÿä¿¡æ¯")
        st.write("")  # æ·»åŠ ç©ºè¡Œ
        
        # æ•°æ®ç»Ÿè®¡
        st.subheader("ğŸ“š æ•°æ®ç»Ÿè®¡")
        if st.session_state.data_ingested:
            st.success("âœ… æ•°æ®å·²æ‘„å–")
        else:
            st.warning("âš ï¸ æ•°æ®æœªæ‘„å–ï¼Œè¯·ç‚¹å‡»å·¦ä¾§'é‡æ–°æ‘„å–æ•°æ®'")
        
        st.write("")
        
        # å¯¹è¯ç»Ÿè®¡
        st.subheader("ğŸ’¬ å¯¹è¯ç»Ÿè®¡")
        st.info(f"å¯¹è¯è½®æ•°: {len(st.session_state.messages) // 2}")
        
        st.write("")
        st.divider()
        
        # æ¨¡å‹é…ç½®
        st.subheader("ğŸ¤– æ¨¡å‹é…ç½®")
        model_name = "æœªåŠ è½½"
        device_info = "æœªæ£€æµ‹"
        
        if st.session_state.rag_system:
            model_name = f"Qwen2.5-Coder-{st.session_state.selected_model}"
            import torch
            device_info = "CPU æ¨¡å¼ï¼ˆRTX 5060 å…¼å®¹æ€§é—®é¢˜ï¼‰"
        
        st.code(f"""
å½“å‰æ¨¡å‹: {model_name}
Embedding æ¨¡å‹: BAAI/bge-small-zh-v1.5
è¿è¡Œè®¾å¤‡: {device_info}
é•œåƒåŠ é€Ÿ: å·²å¯ç”¨ (hf-mirror.com)
        """, language="text")
        
        st.write("")
        st.divider()
        
        # ç³»ç»Ÿé…ç½®
        st.subheader("ğŸ”§ ç³»ç»Ÿé…ç½®")
        st.code(f"""
Chunk Size: {Config.CHUNK_SIZE}
Chunk Overlap: {Config.CHUNK_OVERLAP}
Top K Retrieval: {Config.TOP_K_RETRIEVAL}
Vector DB: {Config.CHROMA_PERSIST_DIRECTORY}
        """, language="text")
        
        st.write("")
        st.divider()
        
        # æ“ä½œæŒ‰é’®
        st.subheader("âš™ï¸ æ“ä½œ")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯å†å²", use_container_width=True):
                st.session_state.messages = []
                st.rerun()
        
        with col2:
            if st.button("ğŸ”„ é‡æ–°åŠ è½½ç³»ç»Ÿ", use_container_width=True):
                st.session_state.rag_system = None
                st.rerun()
        
        with col3:
            if st.button("ğŸ“Š æŸ¥çœ‹ç¼“å­˜", use_container_width=True):
                st.info("ğŸ’¡ è¿è¡Œ `python clear_cache.py` æŸ¥çœ‹å’Œç®¡ç†æ¨¡å‹ç¼“å­˜")
    
    with tab3:
        st.header("ğŸ”§ é…ç½®ä¸å¸®åŠ©")
        st.write("")
        
        # ä½¿ç”¨æŒ‡å—
        st.subheader("ğŸ“– å¿«é€Ÿå¼€å§‹")
        
        st.markdown("""
        ### ğŸš€ ä½¿ç”¨æ­¥éª¤
        
        **1ï¸âƒ£ é€‰æ‹©æ¨¡å‹**
        - åœ¨"å¯¹è¯"æ ‡ç­¾é¡µé€‰æ‹© 1.5Bï¼ˆæ¨èï¼‰æˆ– 7B æ¨¡å‹
        - é¦–æ¬¡ä½¿ç”¨éœ€è¦ä¸‹è½½ï¼Œå·²é…ç½®å›½å†…é•œåƒåŠ é€Ÿ
        
        **2ï¸âƒ£ æ‘„å–æ•°æ®**ï¼ˆå¯é€‰ï¼‰
        - ç‚¹å‡»å·¦ä¾§è¾¹æ çš„"é‡æ–°æ‘„å–æ•°æ®"
        - ç­‰å¾…å¤„ç†å®Œæˆï¼ˆçº¦1-2åˆ†é’Ÿï¼‰
        
        **3ï¸âƒ£ å¼€å§‹æé—®**
        - ç›´æ¥è¾“å…¥é—®é¢˜ï¼ŒæŒ‰å›è½¦å‘é€
        - æˆ–ä½¿ç”¨å·¦ä¾§çš„ç¤ºä¾‹é—®é¢˜å¿«é€Ÿå¼€å§‹
        """)
        
        st.divider()
        
        # æ€§èƒ½è¯´æ˜
        st.subheader("âš¡ æ€§èƒ½è¯´æ˜")
        
        st.info("""
        **å½“å‰è¿è¡Œæ¨¡å¼ï¼šCPU**
        
        ç”±äº RTX 5060 æ˜¯æ–°æ˜¾å¡ï¼Œå½“å‰ PyTorch ç‰ˆæœ¬ä¸æ”¯æŒï¼Œç³»ç»Ÿä½¿ç”¨ CPU æ¨¡å¼è¿è¡Œã€‚
        
        **é¢„æœŸå“åº”æ—¶é—´ï¼š**
        - æ–‡æ¡£æ£€ç´¢ï¼š1-2ç§’
        - ç”Ÿæˆå›ç­”ï¼š15-30ç§’ï¼ˆ1.5Bï¼‰/ 30-60ç§’ï¼ˆ7Bï¼‰
        - æ€»è®¡ï¼šçº¦20-35ç§’
        
        **ä¼˜åŒ–å»ºè®®ï¼š**
        - ä½¿ç”¨ 1.5B æ¨¡å‹ï¼ˆæ›´å¿«ï¼‰
        - é—®é¢˜å°½é‡ç®€æ´æ˜ç¡®
        - ç­‰å¾… PyTorch å®˜æ–¹æ”¯æŒ RTX 50 ç³»åˆ—åå¯åˆ‡æ¢å› GPU
        """)
        
        st.divider()
        
        # æé—®æŠ€å·§
        st.subheader("ğŸ’¡ æé—®æŠ€å·§")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            **âœ… å¥½çš„é—®é¢˜ï¼š**
            - "ä»€ä¹ˆæ˜¯ Type-1 å…‹éš†ï¼Ÿ"
            - "æ¯”è¾ƒ NiCad å’Œ CCFinder"
            - "AST æ–¹æ³•çš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ"
            - "å¦‚ä½•è¯„ä¼°æ£€æµ‹å·¥å…·çš„æ€§èƒ½ï¼Ÿ"
            """)
        
        with col2:
            st.markdown("""
            **âŒ é¿å…ï¼š**
            - è¿‡äºå®½æ³›çš„é—®é¢˜
            - å¤šä¸ªé—®é¢˜æ··åœ¨ä¸€èµ·
            - ä¸ä»£ç å…‹éš†æ£€æµ‹æ— å…³çš„é—®é¢˜
            - è¿‡é•¿çš„ä»£ç ç‰‡æ®µ
            """)
        
        st.divider()
        
        # å¸¸è§é—®é¢˜
        st.subheader("â“ å¸¸è§é—®é¢˜")
        
        with st.expander("Q1: ä¸ºä»€ä¹ˆä½¿ç”¨ CPU è€Œä¸æ˜¯ GPUï¼Ÿ"):
            st.markdown("""
            **åŸå› ï¼š** RTX 5060 æ˜¯ 2024/2025 å¹´çš„æ–°æ˜¾å¡ï¼Œå½“å‰ PyTorch ç‰ˆæœ¬ä¸æ”¯æŒã€‚
            
            **è§£å†³ï¼š** ç­‰å¾… PyTorch å®˜æ–¹å‘å¸ƒæ”¯æŒ RTX 50 ç³»åˆ—çš„ç‰ˆæœ¬ï¼Œæˆ–ä½¿ç”¨ PyTorch Nightly ç‰ˆæœ¬ï¼ˆå®éªŒæ€§ï¼‰ã€‚
            """)
        
        with st.expander("Q2: å“åº”é€Ÿåº¦å¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ"):
            st.markdown("""
            **å»ºè®®ï¼š**
            1. ä½¿ç”¨ 1.5B æ¨¡å‹ï¼ˆæ¯” 7B å¿« 2-3 å€ï¼‰
            2. é—®é¢˜å°½é‡ç®€æ´
            3. è€å¿ƒç­‰å¾…ï¼ˆCPU æ¨¡å¼ç¡®å®è¾ƒæ…¢ï¼‰
            4. è€ƒè™‘å‡çº§ PyTorch ä»¥ä½¿ç”¨ GPU
            """)
        
        with st.expander("Q3: å¦‚ä½•é‡æ–°æ‘„å–æ•°æ®ï¼Ÿ"):
            st.markdown("""
            **æ­¥éª¤ï¼š**
            1. ç‚¹å‡»å·¦ä¾§è¾¹æ çš„"æ•°æ®ç®¡ç†"
            2. ç‚¹å‡»"é‡æ–°æ‘„å–æ•°æ®"æŒ‰é’®
            3. ç­‰å¾…å¤„ç†å®Œæˆ
            
            **æ³¨æ„ï¼š** å¦‚æœæ›´æ”¹äº† data ç›®å½•ä¸­çš„æ–‡æ¡£ï¼Œéœ€è¦é‡æ–°æ‘„å–ã€‚
            """)
        
        with st.expander("Q4: å¦‚ä½•æ¸…é™¤ç¼“å­˜ï¼Ÿ"):
            st.markdown("""
            **æ–¹æ³• 1ï¼š** åœ¨ç»ˆç«¯è¿è¡Œ
            ```bash
            python clear_cache.py
            ```
            
            **æ–¹æ³• 2ï¼š** æ‰‹åŠ¨åˆ é™¤
            ```bash
            Remove-Item -Recurse -Force .\\src\\__pycache__
            ```
            """)
        
        st.divider()
        
        # æ•°æ®ç›®å½•
        st.subheader("ğŸ“ æ•°æ®ç›®å½•ç»“æ„")
        
        st.code("""
data/
â”œâ”€â”€ papers/          # è®ºæ–‡æ–‡æ¡£ï¼ˆPDFã€TXTï¼‰
â”œâ”€â”€ tools_docs/      # å·¥å…·æ–‡æ¡£
â”œâ”€â”€ project_docs/    # é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ examples/        # ç¤ºä¾‹ä»£ç 
â””â”€â”€ chroma/          # å‘é‡æ•°æ®åº“ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
        """, language="text")
        
        st.divider()
        
        # ç³»ç»Ÿè¦æ±‚
        st.subheader("ğŸ’» ç³»ç»Ÿè¦æ±‚")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            **æœ€ä½é…ç½®ï¼š**
            - CPU: 4æ ¸å¿ƒ
            - å†…å­˜: 8GB
            - ç¡¬ç›˜: 10GB å¯ç”¨ç©ºé—´
            - Python: 3.8+
            """)
        
        with col2:
            st.markdown("""
            **æ¨èé…ç½®ï¼š**
            - CPU: 8æ ¸å¿ƒ+
            - å†…å­˜: 16GB+
            - GPU: 8GB+ æ˜¾å­˜ï¼ˆæ”¯æŒçš„æ˜¾å¡ï¼‰
            - ç¡¬ç›˜: 20GB+ å¯ç”¨ç©ºé—´
            """)
        
        st.divider()
        
        # è”ç³»æ–¹å¼
        st.subheader("ğŸ“ è·å–å¸®åŠ©")
        
        st.info("""
        å¦‚æœé‡åˆ°é—®é¢˜ï¼Œå¯ä»¥ï¼š
        1. æŸ¥çœ‹é¡¹ç›® README.md æ–‡æ¡£
        2. æŸ¥çœ‹ USAGE.md è¯¦ç»†ä½¿ç”¨æŒ‡å—
        3. æäº¤ GitHub Issue
        4. è”ç³»é¡¹ç›®ç»´æŠ¤è€…
        """)
        
        st.success("âœ¨ ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼")

if __name__ == "__main__":
    main()
