#!/usr/bin/env python3
"""
GPU æ£€æµ‹å·¥å…· - æ£€æŸ¥ PyTorch æ˜¯å¦èƒ½è¯†åˆ« GPU
"""

import sys

print("=" * 60)
print("GPU æ£€æµ‹å·¥å…·")
print("=" * 60)

# æ£€æŸ¥ PyTorch
try:
    import torch
    print(f"\nâœ… PyTorch å·²å®‰è£…: {torch.__version__}")
    
    # æ£€æŸ¥ CUDA
    print(f"\nğŸ” CUDA å¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"âœ… CUDA ç‰ˆæœ¬: {torch.version.cuda}")
        print(f"âœ… GPU æ•°é‡: {torch.cuda.device_count()}")
        
        for i in range(torch.cuda.device_count()):
            print(f"\nğŸ“Š GPU {i}:")
            print(f"   åç§°: {torch.cuda.get_device_name(i)}")
            print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB")
    else:
        print("\nâŒ CUDA ä¸å¯ç”¨ï¼")
        print("\nå¯èƒ½çš„åŸå› :")
        print("1. æ²¡æœ‰å®‰è£… CUDA ç‰ˆæœ¬çš„ PyTorch")
        print("2. NVIDIA é©±åŠ¨æœªå®‰è£…æˆ–ç‰ˆæœ¬è¿‡æ—§")
        print("3. æ²¡æœ‰ NVIDIA GPU")
        
        print("\nè§£å†³æ–¹æ¡ˆ:")
        print("1. å¸è½½å½“å‰ PyTorch:")
        print("   pip uninstall torch")
        print("\n2. å®‰è£… CUDA ç‰ˆæœ¬çš„ PyTorch:")
        print("   è®¿é—®: https://pytorch.org/get-started/locally/")
        print("   æˆ–è¿è¡Œ: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
        
except ImportError:
    print("\nâŒ PyTorch æœªå®‰è£…ï¼")
    print("è¯·è¿è¡Œ: pip install torch")
    sys.exit(1)

# æ£€æŸ¥ transformers
try:
    import transformers
    print(f"\nâœ… Transformers å·²å®‰è£…: {transformers.__version__}")
except ImportError:
    print("\nâŒ Transformers æœªå®‰è£…ï¼")
    print("è¯·è¿è¡Œ: pip install transformers")

print("\n" + "=" * 60)

